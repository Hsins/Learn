(window.webpackJsonp=window.webpackJsonp||[]).push([[295],{675:function(t,a,s){"use strict";s.r(a);var n=s(8),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"data-preprocessing"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#data-preprocessing"}},[t._v("#")]),t._v(" Data Preprocessing")]),t._v(" "),s("h2",{attrs:{id:"importing-the-dataset"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#importing-the-dataset"}},[t._v("#")]),t._v(" Importing the Dataset")]),t._v(" "),s("h3",{attrs:{id:"implementation-python"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-python"}},[t._v("#")]),t._v(" Implementation (Python)")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# import the libraries")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pylot "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# import the dataset")]),t._v("\ndataset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Data.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nX "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iloc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values     "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create the independent variable matrix")]),t._v("\ny "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("iloc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values       "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create the dependent variable vector")]),t._v("\n")])])]),s("h3",{attrs:{id:"implementation-r"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-r"}},[t._v("#")]),t._v(" Implementation (R)")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# import the dataset")]),t._v("\ndataset "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" read.csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Data.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"missing-data"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#missing-data"}},[t._v("#")]),t._v(" Missing Data")]),t._v(" "),s("p",[t._v("在現實的數據中，資料集中可能會有資料缺失的狀況。為了能夠得到適當的機器學習模型，對於這樣的狀況，我們通常會採用以下的幾種策略進行處理：")]),t._v(" "),s("ul",[s("li",[t._v("直接刪去欄位中資料缺失的該筆資料（但這樣做的危險性較高，因為我們可能會誤刪了重要的資料）")]),t._v(" "),s("li",[t._v("使用整筆資料的平均值、中位數或眾數來填入空缺")])]),t._v(" "),s("h3",{attrs:{id:"implementation-python-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-python-2"}},[t._v("#")]),t._v(" Implementation (Python)")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# taking care of missing data")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("preprocessing "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Imputer\nimputer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Imputer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("missing_value "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nan"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" strategy "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'mean'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" axis "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimputer "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Imputer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" imputer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"implementation-r-2"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-r-2"}},[t._v("#")]),t._v(" Implementation (R)")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# taking care of missing data")]),t._v("\ndataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Age "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ifelse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("is.na"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                     ave"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FUN "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" True"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                     dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Salary "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ifelse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("is.na"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Salary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        ave"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Salary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" FUN "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" True"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Salary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# taking care of missing data")]),t._v("\ndataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("is.na"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" True"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Salary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("is.na"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Age"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" mean"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Salary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" True"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"categorical-data"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#categorical-data"}},[t._v("#")]),t._v(" Categorical Data")]),t._v(" "),s("p",[t._v("數據集中有些資料屬於類別型資料（Categorical Data），比如當前資料中的國家欄位 "),s("code",[t._v("Country")]),t._v(" 與是否購買欄位 "),s("code",[t._v("Purchased")]),t._v("。由於在進行機器學習模型訓練時，會使用到許多數學方程式，因此對於這些以字串或其他型態所儲存的資料必須先轉換為數字，在統計學中將這樣把蒐集到的樣本資料轉換為具有明確意義變數的過程稱為衡量（measurement），在實務上我們會根據衡量尺度（measurement scale）的不同來選擇編碼（encoding）方式。")]),t._v(" "),s("h3",{attrs:{id:"measurement-scale"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#measurement-scale"}},[t._v("#")]),t._v(" Measurement Scale")]),t._v(" "),s("p",[t._v("資料的衡量尺度是給予資料一個實數值，作為比較或計算的基礎，常用的衡量尺度有：")]),t._v(" "),s("ul",[s("li",[t._v("名目尺度（nominal scale）：又稱為類別尺度，類別資料可以進行歸類，彼此間並沒有先後順序或等級關係")]),t._v(" "),s("li",[t._v("順序尺度（ordinal scale）：用以衡量有重要、強弱或大小…程度等級順序的資料")]),t._v(" "),s("li",[t._v("區間尺度（interval scale）：又稱為等距尺度，區間資料可以任意設置原點，數值之間的差距有意義，但比例無意義")]),t._v(" "),s("li",[t._v("比例尺度（ratio scale）：衡量有固定原點的量，也就是資料中存在有 0 值，表示「沒有」的意思")])]),t._v(" "),s("h3",{attrs:{id:"encoding"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#encoding"}},[t._v("#")]),t._v(" Encoding")]),t._v(" "),s("ul",[s("li",[t._v("標籤編碼（Label Encoding）：將每個類別對應到某個數值，不會對原有的欄位進行擴展，通常用於順序尺度")]),t._v(" "),s("li",[t._v("虛擬變數（Dummy Encoding）：當特徵具有 "),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("mi",[t._v("m")])],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("m")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),s("span",{staticClass:"mord mathdefault"},[t._v("m")])])])]),t._v(" 個不同類別標籤時，擴展為對應的 "),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("mi",[t._v("m")]),s("mo",[t._v("−")]),s("mn",[t._v("1")])],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("m-1")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"0.66666em","vertical-align":"-0.08333em"}}),s("span",{staticClass:"mord mathdefault"},[t._v("m")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),s("span",{staticClass:"mbin"},[t._v("−")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}})]),s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"0.64444em","vertical-align":"0em"}}),s("span",{staticClass:"mord"},[t._v("1")])])])]),t._v(" 個二進制特徵，作為基準的特徵將被忽略，通常用於名目尺度")]),t._v(" "),s("li",[t._v("獨熱編碼（One Hot Encoding）：當特徵具有 "),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("mi",[t._v("m")])],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("m")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),s("span",{staticClass:"mord mathdefault"},[t._v("m")])])])]),t._v(" 個不同類別標籤時，擴展為對應的 "),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("mi",[t._v("m")])],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("m")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),s("span",{staticClass:"mord mathdefault"},[t._v("m")])])])]),t._v(" 個二進制特徵，通常用於名目尺度。容易導致共線性的問題，從而使得模型參數估計不準確")])]),t._v(" "),s("h3",{attrs:{id:"implementation-python-3"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-python-3"}},[t._v("#")]),t._v(" Implementation (Python)")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Encoding categorical data")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("preprocessing "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LabelEncoder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" OneHotEncoder\nlabelencoder_X "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LabelEncoder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nX"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" labelencoder_X"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nonehotencoder "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" OneHotEncoder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("categorical_features "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nX "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" onehotencoder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toarray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlabelencoder_y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LabelEncoder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" labelencoder_y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"implementation-r-3"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-r-3"}},[t._v("#")]),t._v(" Implementation (R)")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Encoding categorical data")]),t._v("\ndataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Country "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" factor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Country"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                         levels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'France'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Spain'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Germany'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                         labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Purchased "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" factor"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Purchased"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                           levels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'No'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Yes'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                           labels "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"splitting-the-dataset-into-to-training-set-and-test-set"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#splitting-the-dataset-into-to-training-set-and-test-set"}},[t._v("#")]),t._v(" Splitting the Dataset into to Training Set and Test Set")]),t._v(" "),s("h3",{attrs:{id:"implementation-python-4"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-python-4"}},[t._v("#")]),t._v(" Implementation (Python)")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Splitting the dataset into the Training Set and Test Set")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" train_test_split\nX_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_test_split"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_size "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"implementation-r-4"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-r-4"}},[t._v("#")]),t._v(" Implementation (R)")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Splitting the dataset into the Training Set and Test Set")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# install.package('caTools')")]),t._v("\nlibrary"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("caTools"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nset.seed"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsplit "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sample.split"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("Purchased"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" SplitRatio "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntraining_set "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" subset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" split "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_set "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" subset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" split "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("FALSE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"feature-scaling"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#feature-scaling"}},[t._v("#")]),t._v(" Feature Scaling")]),t._v(" "),s("h3",{attrs:{id:"standardisation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#standardisation"}},[t._v("#")]),t._v(" Standardisation")]),t._v(" "),s("p",{staticClass:"katex-block"},[s("span",{staticClass:"katex-display"},[s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("msub",[s("mi",[t._v("x")]),s("mtext",[t._v("stand")])],1),s("mo",[t._v("=")]),s("mfrac",[s("mrow",[s("mi",[t._v("x")]),s("mo",[t._v("−")]),s("mtext",[t._v("mean")]),s("mo",{attrs:{stretchy:"false"}},[t._v("(")]),s("mi",[t._v("x")]),s("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1),s("mrow",[s("mtext",[t._v("Standard Deviation")]),s("mo",{attrs:{stretchy:"false"}},[t._v("(")]),s("mi",[t._v("x")]),s("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1)],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("x_{\\text{stand}} = \\frac{x - \\text{mean}(x)}{\\text{Standard Deviation}(x)}\n")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"0.58056em","vertical-align":"-0.15em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathdefault"},[t._v("x")]),s("span",{staticClass:"msupsub"},[s("span",{staticClass:"vlist-t vlist-t2"},[s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.33610799999999996em"}},[s("span",{staticStyle:{top:"-2.5500000000000003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),s("span",{staticClass:"sizing reset-size6 size3 mtight"},[s("span",{staticClass:"mord mtight"},[s("span",{staticClass:"mord text mtight"},[s("span",{staticClass:"mord mtight"},[t._v("stand")])])])])])]),s("span",{staticClass:"vlist-s"},[t._v("​")])]),s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.15em"}},[s("span")])])])])]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),s("span",{staticClass:"mrel"},[t._v("=")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"2.363em","vertical-align":"-0.936em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mopen nulldelimiter"}),s("span",{staticClass:"mfrac"},[s("span",{staticClass:"vlist-t vlist-t2"},[s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"1.427em"}},[s("span",{staticStyle:{top:"-2.314em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord text"},[s("span",{staticClass:"mord"},[t._v("Standard Deviation")])]),s("span",{staticClass:"mopen"},[t._v("(")]),s("span",{staticClass:"mord mathdefault"},[t._v("x")]),s("span",{staticClass:"mclose"},[t._v(")")])])]),s("span",{staticStyle:{top:"-3.23em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),s("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),s("span",{staticStyle:{top:"-3.677em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathdefault"},[t._v("x")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),s("span",{staticClass:"mbin"},[t._v("−")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),s("span",{staticClass:"mord text"},[s("span",{staticClass:"mord"},[t._v("mean")])]),s("span",{staticClass:"mopen"},[t._v("(")]),s("span",{staticClass:"mord mathdefault"},[t._v("x")]),s("span",{staticClass:"mclose"},[t._v(")")])])])]),s("span",{staticClass:"vlist-s"},[t._v("​")])]),s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.936em"}},[s("span")])])])]),s("span",{staticClass:"mclose nulldelimiter"})])])])])])]),t._v(" "),s("h3",{attrs:{id:"normalisation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#normalisation"}},[t._v("#")]),t._v(" Normalisation")]),t._v(" "),s("p",{staticClass:"katex-block"},[s("span",{staticClass:"katex-display"},[s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",[s("semantics",[s("mrow",[s("msub",[s("mi",[t._v("x")]),s("mtext",[t._v("norm")])],1),s("mo",[t._v("=")]),s("mfrac",[s("mrow",[s("mi",[t._v("x")]),s("mo",[t._v("−")]),s("mi",[t._v("min")]),s("mo",[t._v("⁡")]),s("mrow",[s("mo",{attrs:{stretchy:"false"}},[t._v("(")]),s("mi",[t._v("x")]),s("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1),s("mrow",[s("mi",[t._v("max")]),s("mo",[t._v("⁡")]),s("mrow",[s("mo",{attrs:{stretchy:"false"}},[t._v("(")]),s("mi",[t._v("x")]),s("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1),s("mo",[t._v("−")]),s("mi",[t._v("min")]),s("mo",[t._v("⁡")]),s("mrow",[s("mo",{attrs:{stretchy:"false"}},[t._v("(")]),s("mi",[t._v("x")]),s("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1)],1)],1)],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("x_{\\text{norm}} = \\frac{x - \\min{(x)}}{\\max{(x)} - \\min{(x)}}\n")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"0.58056em","vertical-align":"-0.15em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathdefault"},[t._v("x")]),s("span",{staticClass:"msupsub"},[s("span",{staticClass:"vlist-t vlist-t2"},[s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.151392em"}},[s("span",{staticStyle:{top:"-2.5500000000000003em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),s("span",{staticClass:"sizing reset-size6 size3 mtight"},[s("span",{staticClass:"mord mtight"},[s("span",{staticClass:"mord text mtight"},[s("span",{staticClass:"mord mtight"},[t._v("norm")])])])])])]),s("span",{staticClass:"vlist-s"},[t._v("​")])]),s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.15em"}},[s("span")])])])])]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),s("span",{staticClass:"mrel"},[t._v("=")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"2.363em","vertical-align":"-0.936em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mopen nulldelimiter"}),s("span",{staticClass:"mfrac"},[s("span",{staticClass:"vlist-t vlist-t2"},[s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"1.427em"}},[s("span",{staticStyle:{top:"-2.314em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mop"},[t._v("max")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.16666666666666666em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mopen"},[t._v("(")]),s("span",{staticClass:"mord mathdefault"},[t._v("x")]),s("span",{staticClass:"mclose"},[t._v(")")])]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),s("span",{staticClass:"mbin"},[t._v("−")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),s("span",{staticClass:"mop"},[t._v("min")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.16666666666666666em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mopen"},[t._v("(")]),s("span",{staticClass:"mord mathdefault"},[t._v("x")]),s("span",{staticClass:"mclose"},[t._v(")")])])])]),s("span",{staticStyle:{top:"-3.23em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),s("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),s("span",{staticStyle:{top:"-3.677em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathdefault"},[t._v("x")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),s("span",{staticClass:"mbin"},[t._v("−")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222222222222222em"}}),s("span",{staticClass:"mop"},[t._v("min")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.16666666666666666em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mopen"},[t._v("(")]),s("span",{staticClass:"mord mathdefault"},[t._v("x")]),s("span",{staticClass:"mclose"},[t._v(")")])])])])]),s("span",{staticClass:"vlist-s"},[t._v("​")])]),s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.936em"}},[s("span")])])])]),s("span",{staticClass:"mclose nulldelimiter"})])])])])])]),t._v(" "),s("h3",{attrs:{id:"implementation-python-5"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-python-5"}},[t._v("#")]),t._v(" Implementation (Python)")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Feature Scaling")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("preprocessing "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" StandardScaler\nsc_X "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StandardScaler"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nX_train "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc_X"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nX_test "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc_X"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transform"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"implementation-r-5"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#implementation-r-5"}},[t._v("#")]),t._v(" Implementation (R)")]),t._v(" "),s("div",{staticClass:"language-r extra-class"},[s("pre",{pre:!0,attrs:{class:"language-r"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Feature Scaling")]),t._v("\ntraining_set"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scale"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("training_set"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntest_set"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scale"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("test_set"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=e.exports}}]);